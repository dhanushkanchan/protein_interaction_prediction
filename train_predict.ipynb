{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Seq8_Nov2023.xlsx\"\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Dist 1</th>\n",
       "      <th>Bind 1</th>\n",
       "      <th>Dist 2</th>\n",
       "      <th>Bind 2</th>\n",
       "      <th>Dist 3</th>\n",
       "      <th>Bind 3</th>\n",
       "      <th>Ave. dist</th>\n",
       "      <th>std. Dist</th>\n",
       "      <th>Ave. bind</th>\n",
       "      <th>Std. Bind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WFDGRAPR</td>\n",
       "      <td>8.30</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>7.43</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>5.41</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>7.046667</td>\n",
       "      <td>1.482644</td>\n",
       "      <td>-6.666667</td>\n",
       "      <td>0.251661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PPSPRPRR</td>\n",
       "      <td>5.69</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>8.78</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>4.83</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>6.433333</td>\n",
       "      <td>2.077266</td>\n",
       "      <td>-6.633333</td>\n",
       "      <td>0.450925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RGGGRPPR</td>\n",
       "      <td>4.85</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>6.78</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>5.67</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>5.766667</td>\n",
       "      <td>0.968624</td>\n",
       "      <td>-6.600000</td>\n",
       "      <td>0.264575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASFSRAKR</td>\n",
       "      <td>5.37</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>4.82</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>4.80</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>4.996667</td>\n",
       "      <td>0.323471</td>\n",
       "      <td>-6.500000</td>\n",
       "      <td>0.624500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRPRRPPR</td>\n",
       "      <td>5.56</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>4.82</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>5.56</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>5.313333</td>\n",
       "      <td>0.427239</td>\n",
       "      <td>-6.500000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2457</th>\n",
       "      <td>DKSRKIAR</td>\n",
       "      <td>4.82</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>4.81</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>7.79</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>5.806667</td>\n",
       "      <td>1.717624</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>VCKKRQHR</td>\n",
       "      <td>5.46</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>5.17</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>5.42</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>0.157162</td>\n",
       "      <td>-4.466667</td>\n",
       "      <td>0.450925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>SSKRRKRR</td>\n",
       "      <td>6.68</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>4.82</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>4.83</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>5.443333</td>\n",
       "      <td>1.070996</td>\n",
       "      <td>-4.466667</td>\n",
       "      <td>0.493288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>KKSKKSSR</td>\n",
       "      <td>4.88</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>5.82</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>4.77</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>5.156667</td>\n",
       "      <td>0.577090</td>\n",
       "      <td>-4.433333</td>\n",
       "      <td>0.152753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>TEKKKKKR</td>\n",
       "      <td>6.81</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>5.66</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>5.50</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>5.990000</td>\n",
       "      <td>0.714633</td>\n",
       "      <td>-4.200000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2462 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sequence  Dist 1  Bind 1  Dist 2  Bind 2  Dist 3   Bind 3  Ave. dist  \\\n",
       "0     WFDGRAPR    8.30    -6.9    7.43    -6.4     5.41    -6.7   7.046667   \n",
       "1     PPSPRPRR    5.69    -6.6    8.78    -6.2     4.83    -7.1   6.433333   \n",
       "2     RGGGRPPR    4.85    -6.5    6.78    -6.9     5.67    -6.4   5.766667   \n",
       "3     ASFSRAKR    5.37    -7.0    4.82    -6.7     4.80    -5.8   4.996667   \n",
       "4     TRPRRPPR    5.56    -6.3    4.82    -6.5     5.56    -6.7   5.313333   \n",
       "...        ...     ...     ...     ...     ...      ...     ...        ...   \n",
       "2457  DKSRKIAR    4.82    -4.2    4.81    -4.5     7.79    -4.8   5.806667   \n",
       "2458  VCKKRQHR    5.46    -4.9    5.17    -4.0     5.42    -4.5   5.350000   \n",
       "2459  SSKRRKRR    6.68    -4.8    4.82    -3.9     4.83    -4.7   5.443333   \n",
       "2460  KKSKKSSR    4.88    -4.6    5.82    -4.4     4.77    -4.3   5.156667   \n",
       "2461  TEKKKKKR    6.81    -4.3    5.66    -4.2     5.50    -4.1   5.990000   \n",
       "\n",
       "      std. Dist  Ave. bind  Std. Bind  \n",
       "0      1.482644  -6.666667   0.251661  \n",
       "1      2.077266  -6.633333   0.450925  \n",
       "2      0.968624  -6.600000   0.264575  \n",
       "3      0.323471  -6.500000   0.624500  \n",
       "4      0.427239  -6.500000   0.200000  \n",
       "...         ...        ...        ...  \n",
       "2457   1.717624  -4.500000   0.300000  \n",
       "2458   0.157162  -4.466667   0.450925  \n",
       "2459   1.070996  -4.466667   0.493288  \n",
       "2460   0.577090  -4.433333   0.152753  \n",
       "2461   0.714633  -4.200000   0.100000  \n",
       "\n",
       "[2462 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['W', 'F', 'D', 'G', 'R', 'A', 'P', 'S', 'K', 'T', 'Q', 'V', 'Y',\n",
       "       'L', 'I', 'H', 'E', 'N', 'C', 'M'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data = pd.get_dummies(df['Sequence'].apply(list).explode(), prefix='', prefix_sep='')\n",
    "df['Sequence'].apply(list).explode().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acids = sorted(['W', 'F', 'D', 'G', 'R', 'A', 'P', 'S', 'K', 'T', 'Q', 'V', 'Y', 'L', 'I', 'H', 'E', 'N', 'C', 'M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequence(seq):\n",
    "    temp = [[0]*20 for i in range(8)]\n",
    "    for i in range(8):\n",
    "        for j in range(20):\n",
    "            if seq[i] == amino_acids[j]:\n",
    "                temp[i][j] = 1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['encoded'] = df.apply(lambda row: encode_sequence(row['Sequence']), axis=1)\n",
    "df['encoded'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['encoded']\n",
    "y = df['Ave. bind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of reshaped data: (2462, 8, 20)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the encoded sequences\n",
    "encoded_sequence_array = np.array(x)\n",
    "num_samples = len(encoded_sequence_array)\n",
    "x_reshaped = np.empty((num_samples, 8, 20))\n",
    "for i in range(num_samples):\n",
    "    x_reshaped[i] = encoded_sequence_array[i]\n",
    "    \n",
    "print(\"Shape of reshaped data:\", x_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_reshaped, y, test_size=0.20, random_state=502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/31 [==============================] - 1s 12ms/step - loss: 4.9449 - val_loss: 3.6362\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.1255 - val_loss: 0.3485\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.3136 - val_loss: 0.2893\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2859 - val_loss: 0.2799\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2764 - val_loss: 0.2740\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2658 - val_loss: 0.2656\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2500 - val_loss: 0.2542\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2400 - val_loss: 0.2486\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2358 - val_loss: 0.2399\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2273 - val_loss: 0.2380\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.2259 - val_loss: 0.2357\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2233 - val_loss: 0.2343\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2223 - val_loss: 0.2335\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2239 - val_loss: 0.2331\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2238 - val_loss: 0.2319\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2199 - val_loss: 0.2323\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2178 - val_loss: 0.2330\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2183 - val_loss: 0.2386\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2194 - val_loss: 0.2404\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2198 - val_loss: 0.2375\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2210 - val_loss: 0.2452\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2184 - val_loss: 0.2315\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.2186 - val_loss: 0.2312\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2194 - val_loss: 0.2408\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2186 - val_loss: 0.2378\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2205 - val_loss: 0.2399\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2222 - val_loss: 0.2335\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2171 - val_loss: 0.2388\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2177 - val_loss: 0.2305\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2199 - val_loss: 0.2614\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2268 - val_loss: 0.2393\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.2202 - val_loss: 0.2309\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.2192 - val_loss: 0.2317\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2181 - val_loss: 0.2304\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2188 - val_loss: 0.2323\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2208 - val_loss: 0.2374\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2175 - val_loss: 0.2349\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2178 - val_loss: 0.2407\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2189 - val_loss: 0.2477\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2176 - val_loss: 0.2536\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2204 - val_loss: 0.2296\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2158 - val_loss: 0.2297\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2164 - val_loss: 0.2304\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2231 - val_loss: 0.2344\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2167 - val_loss: 0.2351\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2156 - val_loss: 0.2298\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.2148 - val_loss: 0.2304\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2144 - val_loss: 0.2364\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2196 - val_loss: 0.2303\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2147 - val_loss: 0.2307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x304fbf4c0>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM implementation\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(8, x_reshaped.shape[2])))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=64, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/31 [==============================] - 1s 6ms/step - loss: 3.4834 - val_loss: 1.4571\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5854 - val_loss: 0.3323\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3033 - val_loss: 0.2911\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2959 - val_loss: 0.2902\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2945 - val_loss: 0.2900\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2939 - val_loss: 0.2896\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2936 - val_loss: 0.2883\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2928 - val_loss: 0.2873\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2911 - val_loss: 0.2857\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2896 - val_loss: 0.2842\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2867 - val_loss: 0.2854\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2872 - val_loss: 0.2790\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2833 - val_loss: 0.2765\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2745 - val_loss: 0.2701\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2641 - val_loss: 0.2661\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2505 - val_loss: 0.2543\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2346 - val_loss: 0.2473\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2264 - val_loss: 0.2452\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2254 - val_loss: 0.2450\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2223 - val_loss: 0.2438\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2202 - val_loss: 0.2428\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2184 - val_loss: 0.2409\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2196 - val_loss: 0.2424\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2192 - val_loss: 0.2377\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2140 - val_loss: 0.2383\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2185 - val_loss: 0.2386\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2144 - val_loss: 0.2398\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2126 - val_loss: 0.2384\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2125 - val_loss: 0.2407\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2134 - val_loss: 0.2436\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2109 - val_loss: 0.2361\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2087 - val_loss: 0.2359\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2087 - val_loss: 0.2398\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.2115 - val_loss: 0.2451\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2092 - val_loss: 0.2378\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2083 - val_loss: 0.2389\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2102 - val_loss: 0.2407\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2124 - val_loss: 0.2440\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2092 - val_loss: 0.2456\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2056 - val_loss: 0.2468\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2055 - val_loss: 0.2371\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2039 - val_loss: 0.2391\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2039 - val_loss: 0.2362\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2065 - val_loss: 0.2387\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2081 - val_loss: 0.2423\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2014 - val_loss: 0.2430\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2050 - val_loss: 0.2436\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2005 - val_loss: 0.2396\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1985 - val_loss: 0.2382\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.1982 - val_loss: 0.2418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x3110f3c10>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN implementation\n",
    "model = Sequential()\n",
    "\n",
    "model.add(SimpleRNN(units=50, input_shape=(8, x_reshaped.shape[2])))\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=64, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 994us/step - loss: 0.2307\n",
      "Mean Absolute Error on Test Set: 0.23068930208683014\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mean_error = model.evaluate(x_test, y_test)\n",
    "print(f\"Mean Absolute Error on Test Set: {mean_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test_df['encoded'] = x_test.tolist()\n",
    "test_df['predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(encoded_seq):\n",
    "    decoded_seq = \"\"\n",
    "    for i in range(len(encoded_seq)):\n",
    "        # Find the index of 1 in each row of the encoded sequence\n",
    "        index = encoded_seq[i].index(1)\n",
    "        # Use the index to get the corresponding amino acid from the encoding list\n",
    "        decoded_seq += amino_acids[index]\n",
    "    return decoded_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Sequence'] = test_df['encoded'].apply(decode_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded</th>\n",
       "      <th>predictions</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>-5.799766</td>\n",
       "      <td>PQALRTTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>-5.492521</td>\n",
       "      <td>YISKRSKR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>-5.750213</td>\n",
       "      <td>DLLGHARR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>-5.810551</td>\n",
       "      <td>TPLPRTRR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>-5.836238</td>\n",
       "      <td>PVDARHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>-5.580463</td>\n",
       "      <td>TKLTRPVR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,...</td>\n",
       "      <td>-5.597978</td>\n",
       "      <td>KEPARHRR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>-5.275733</td>\n",
       "      <td>NQPKRKKR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>-5.348962</td>\n",
       "      <td>LERMIRRR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>-5.357562</td>\n",
       "      <td>TRQHRHKR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               encoded  predictions  Sequence\n",
       "0    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...    -5.799766  PQALRTTR\n",
       "1    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...    -5.492521  YISKRSKR\n",
       "2    [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...    -5.750213  DLLGHARR\n",
       "3    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...    -5.810551  TPLPRTRR\n",
       "4    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...    -5.836238  PVDARHAR\n",
       "..                                                 ...          ...       ...\n",
       "488  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...    -5.580463  TKLTRPVR\n",
       "489  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,...    -5.597978  KEPARHRR\n",
       "490  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...    -5.275733  NQPKRKKR\n",
       "491  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...    -5.348962  LERMIRRR\n",
       "492  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...    -5.357562  TRQHRHKR\n",
       "\n",
       "[493 rows x 3 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
